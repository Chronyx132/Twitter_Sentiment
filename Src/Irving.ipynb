{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT1244 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as re\n",
    "import heapq as heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import random as random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.decomposition import PCA\n",
    "import torch as torch\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer, BertTokenizerFast\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_test, y_pred):\n",
    "    return sum(y_test == y_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1  0  is upset that he can't update his Facebook by ...\n",
       "2  0  @Kenichan I dived many times for the ball. Man...\n",
       "3  0    my whole body feels itchy and like its on fire \n",
       "4  0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"../Data/Raw/dataset.csv\", header=None)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base', use_fast=True)\n",
    "model = AutoModel.from_pretrained('vinai/bertweet-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    return output.last_hidden_state[:, 0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = tweets[1].apply(lambda x: bert_encode(x))\n",
    "data = np.array(list(map(lambda x: x[0], sentence_vectors)))\n",
    "data_frame = pd.DataFrame(data)\n",
    "data_frame.to_csv(\"../Data/Cleaned/BERT_Vectors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bert_Encoded_Text = pd.read_csv(\"../Data/Cleaned/BERT_Vectors.csv\").iloc[: , 1:]\n",
    "X = Bert_Encoded_Text\n",
    "y = tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6896\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [i for i in range (1,31)]\n",
    "scores = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score = cross_val_score(knn, X, y, cv=5)\n",
    "    scores.append(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(map(lambda x: float(x), scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.65648,\n",
       " 0.64578,\n",
       " 0.67612,\n",
       " 0.6713899999999999,\n",
       " 0.68684,\n",
       " 0.68375,\n",
       " 0.69182,\n",
       " 0.6899200000000001,\n",
       " 0.69536,\n",
       " 0.69342,\n",
       " 0.69888,\n",
       " 0.6965199999999999,\n",
       " 0.69996,\n",
       " 0.6984300000000001,\n",
       " 0.70131,\n",
       " 0.69845,\n",
       " 0.70112,\n",
       " 0.70009,\n",
       " 0.70248,\n",
       " 0.70123,\n",
       " 0.70323,\n",
       " 0.7026899999999999,\n",
       " 0.7042700000000001,\n",
       " 0.7030299999999999,\n",
       " 0.7047000000000001,\n",
       " 0.70383,\n",
       " 0.7055499999999999,\n",
       " 0.7040599999999999,\n",
       " 0.70563,\n",
       " 0.70394]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.563"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy Score')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x = k_values, y = scores, marker = 'o')\n",
    "plt.xlabel(\"K Values\")\n",
    "plt.ylabel(\"Accuracy Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_val(model):\n",
    "    y_hat = model.predict(X_test)\n",
    "    return float((sum((y_hat >= 0.5) == y_test)/len(y_test))[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 768)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y = y.reshape(-1, 1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 24ms/step - accuracy: 0.7555 - loss: 0.4895 - val_accuracy: 0.8087 - val_loss: 0.4175\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8343 - loss: 0.3721 - val_accuracy: 0.8170 - val_loss: 0.4083\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8590 - loss: 0.3243 - val_accuracy: 0.8084 - val_loss: 0.4241\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 23ms/step - accuracy: 0.8829 - loss: 0.2716 - val_accuracy: 0.8056 - val_loss: 0.4378\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9123 - loss: 0.2092 - val_accuracy: 0.8028 - val_loss: 0.4997\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9401 - loss: 0.1465 - val_accuracy: 0.7960 - val_loss: 0.6066\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9570 - loss: 0.1112 - val_accuracy: 0.7929 - val_loss: 0.7427\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9666 - loss: 0.0873 - val_accuracy: 0.7914 - val_loss: 0.8501\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9724 - loss: 0.0744 - val_accuracy: 0.7957 - val_loss: 0.9503\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9761 - loss: 0.0623 - val_accuracy: 0.7958 - val_loss: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28387778b20>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model.add(Dense(512, input_dim=768, activation='gelu'))\n",
    "model.add(Dense(512, activation='gelu'))\n",
    "model.add(Dense(512, activation='gelu'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,758,661</span> (10.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,758,661\u001b[0m (10.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">919,553</span> (3.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m919,553\u001b[0m (3.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,839,108</span> (7.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,839,108\u001b[0m (7.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.83"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
    "model.summary()\n",
    "accuracy_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.7626 - loss: 0.4868 - val_accuracy: 0.8098 - val_loss: 0.4147\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8294 - loss: 0.3768 - val_accuracy: 0.8158 - val_loss: 0.4102\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8572 - loss: 0.3260 - val_accuracy: 0.8128 - val_loss: 0.4185\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8839 - loss: 0.2694 - val_accuracy: 0.8049 - val_loss: 0.4652\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.9116 - loss: 0.2079 - val_accuracy: 0.8017 - val_loss: 0.5255\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9419 - loss: 0.1480 - val_accuracy: 0.7956 - val_loss: 0.6211\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9587 - loss: 0.1073 - val_accuracy: 0.7945 - val_loss: 0.7989\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9670 - loss: 0.0847 - val_accuracy: 0.7911 - val_loss: 0.8119\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.9714 - loss: 0.0758 - val_accuracy: 0.7947 - val_loss: 0.9442\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.9779 - loss: 0.0614 - val_accuracy: 0.7857 - val_loss: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2838c48d4b0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model.add(Dense(512, input_dim=768, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7240 - loss: 0.5444 - val_accuracy: 0.8116 - val_loss: 0.4202\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8113 - loss: 0.4163 - val_accuracy: 0.8169 - val_loss: 0.4030\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8241 - loss: 0.3898 - val_accuracy: 0.8189 - val_loss: 0.4025\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8328 - loss: 0.3729 - val_accuracy: 0.8213 - val_loss: 0.3973\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8402 - loss: 0.3593 - val_accuracy: 0.8213 - val_loss: 0.3951\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8481 - loss: 0.3433 - val_accuracy: 0.8227 - val_loss: 0.3916\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8521 - loss: 0.3341 - val_accuracy: 0.8214 - val_loss: 0.3998\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8582 - loss: 0.3244 - val_accuracy: 0.8182 - val_loss: 0.4032\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8610 - loss: 0.3137 - val_accuracy: 0.8214 - val_loss: 0.4061\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8642 - loss: 0.3052 - val_accuracy: 0.8219 - val_loss: 0.4026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2838c0e9bd0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model0 = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model0.add(Dense(512, input_dim=768, activation='gelu'))\n",
    "model0.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model0.add(Dense(256, activation='gelu'))\n",
    "model0.add(Dropout(0.3))\n",
    "model0.add(Dense(128, activation='gelu'))\n",
    "model0.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model0.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model0.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model0.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,245</span> (6.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,674,245\u001b[0m (6.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">558,081</span> (2.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m558,081\u001b[0m (2.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,116,164</span> (4.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,116,164\u001b[0m (4.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_val(model0)\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7226 - loss: 0.5420 - val_accuracy: 0.8038 - val_loss: 0.4254\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8142 - loss: 0.4143 - val_accuracy: 0.8177 - val_loss: 0.4049\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8242 - loss: 0.3897 - val_accuracy: 0.8194 - val_loss: 0.4021\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8322 - loss: 0.3775 - val_accuracy: 0.8217 - val_loss: 0.3957\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8393 - loss: 0.3632 - val_accuracy: 0.8253 - val_loss: 0.3913\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8435 - loss: 0.3528 - val_accuracy: 0.8247 - val_loss: 0.3897\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8473 - loss: 0.3421 - val_accuracy: 0.8210 - val_loss: 0.3950\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8511 - loss: 0.3381 - val_accuracy: 0.8217 - val_loss: 0.3961\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8574 - loss: 0.3279 - val_accuracy: 0.8229 - val_loss: 0.3961\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8599 - loss: 0.3183 - val_accuracy: 0.8228 - val_loss: 0.3977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28387b1a650>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model1 = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model1.add(Dense(512, input_dim=768, activation='relu'))\n",
    "model1.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model1.add(Dense(256, activation='gelu'))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(128, activation='mish'))\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,245</span> (6.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,674,245\u001b[0m (6.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">558,081</span> (2.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m558,081\u001b[0m (2.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,116,164</span> (4.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,116,164\u001b[0m (4.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.105"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary()\n",
    "accuracy_val(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.7567 - loss: 0.4998 - val_accuracy: 0.6636 - val_loss: 0.6819\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 32ms/step - accuracy: 0.8231 - loss: 0.3953 - val_accuracy: 0.7261 - val_loss: 0.5593\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 54ms/step - accuracy: 0.8341 - loss: 0.3744 - val_accuracy: 0.7588 - val_loss: 0.5016\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 25ms/step - accuracy: 0.8375 - loss: 0.3657 - val_accuracy: 0.7053 - val_loss: 0.5725\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 58ms/step - accuracy: 0.8443 - loss: 0.3556 - val_accuracy: 0.7190 - val_loss: 0.5409\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 58ms/step - accuracy: 0.8493 - loss: 0.3441 - val_accuracy: 0.7140 - val_loss: 0.5832\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 56ms/step - accuracy: 0.8506 - loss: 0.3364 - val_accuracy: 0.7413 - val_loss: 0.5321\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - accuracy: 0.8540 - loss: 0.3324 - val_accuracy: 0.7243 - val_loss: 0.5477\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 180ms/step - accuracy: 0.8569 - loss: 0.3267 - val_accuracy: 0.6844 - val_loss: 0.6371\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - accuracy: 0.8612 - loss: 0.3162 - val_accuracy: 0.7279 - val_loss: 0.5782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28399e7dd50>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model2 = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model2.add(Dense(512, input_dim=768, activation='gelu'))\n",
    "model2.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model2.add(Dense(256, activation='gelu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(128, activation='gelu'))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,245</span> (6.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,674,245\u001b[0m (6.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">558,081</span> (2.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m558,081\u001b[0m (2.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,116,164</span> (4.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,116,164\u001b[0m (4.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.48"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.summary()\n",
    "accuracy_val(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 51ms/step - accuracy: 0.8614 - loss: 0.3103 - val_accuracy: 0.7191 - val_loss: 0.5553\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 48ms/step - accuracy: 0.8638 - loss: 0.3022 - val_accuracy: 0.6758 - val_loss: 0.6828\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 425ms/step - accuracy: 0.8710 - loss: 0.2951 - val_accuracy: 0.7150 - val_loss: 0.5909\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 63ms/step - accuracy: 0.8668 - loss: 0.2921 - val_accuracy: 0.7010 - val_loss: 0.6709\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 60ms/step - accuracy: 0.8734 - loss: 0.2841 - val_accuracy: 0.7382 - val_loss: 0.5234\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 62ms/step - accuracy: 0.8762 - loss: 0.2785 - val_accuracy: 0.7085 - val_loss: 0.6074\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 159ms/step - accuracy: 0.8772 - loss: 0.2724 - val_accuracy: 0.7040 - val_loss: 0.6178\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.8786 - loss: 0.2707 - val_accuracy: 0.7111 - val_loss: 0.6427\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8825 - loss: 0.2668 - val_accuracy: 0.7117 - val_loss: 0.6255\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - accuracy: 0.8836 - loss: 0.2616 - val_accuracy: 0.7239 - val_loss: 0.6564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2839c816ce0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model3 = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model3.add(Dense(512, input_dim=768, activation='gelu'))\n",
    "model3.add(Dense(512, input_dim=768, activation='mish'))\n",
    "model3.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model3.add(Dense(256, activation='gelu'))\n",
    "model3.add(Dense(256, activation='tanh'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(128, activation='gelu'))\n",
    "model3.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.004999999999995"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 55ms/step - accuracy: 0.8883 - loss: 0.2527 - val_accuracy: 0.7014 - val_loss: 0.7275\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 54ms/step - accuracy: 0.8883 - loss: 0.2509 - val_accuracy: 0.7506 - val_loss: 0.5956\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 53ms/step - accuracy: 0.8885 - loss: 0.2484 - val_accuracy: 0.7148 - val_loss: 0.6902\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 51ms/step - accuracy: 0.8903 - loss: 0.2469 - val_accuracy: 0.7379 - val_loss: 0.6105\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.8916 - loss: 0.2402 - val_accuracy: 0.7344 - val_loss: 0.5432\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.8931 - loss: 0.2396 - val_accuracy: 0.7288 - val_loss: 0.7637\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8966 - loss: 0.2348 - val_accuracy: 0.7409 - val_loss: 0.6239\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8969 - loss: 0.2313 - val_accuracy: 0.7440 - val_loss: 0.6830\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.8996 - loss: 0.2281 - val_accuracy: 0.7578 - val_loss: 0.6661\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9018 - loss: 0.2224 - val_accuracy: 0.7466 - val_loss: 0.5647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28387724a90>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model4 = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model4.add(Dense(512, input_dim=768, activation='mish'))\n",
    "model4.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model4.add(Dense(256, activation='tanh'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(128, activation='gelu'))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model4.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model4.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.37"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7241 - loss: 0.5562 - val_accuracy: 0.8088 - val_loss: 0.4263\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.4224 - val_accuracy: 0.8156 - val_loss: 0.4085\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8235 - loss: 0.3960 - val_accuracy: 0.8207 - val_loss: 0.4011\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.3915 - val_accuracy: 0.8231 - val_loss: 0.3928\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8302 - loss: 0.3809 - val_accuracy: 0.8224 - val_loss: 0.3959\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.3743 - val_accuracy: 0.8250 - val_loss: 0.3910\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.3710 - val_accuracy: 0.8246 - val_loss: 0.3898\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3649 - val_accuracy: 0.8258 - val_loss: 0.3865\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8415 - loss: 0.3599 - val_accuracy: 0.8246 - val_loss: 0.3879\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8456 - loss: 0.3551 - val_accuracy: 0.8244 - val_loss: 0.3887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2838e86d3f0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (80,000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model5 = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model5.add(Dense(64, input_dim=768, activation='mish'))\n",
    "model5.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model5.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model5.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.78999999999999"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.7142 - loss: 0.5677 - val_accuracy: 0.8089 - val_loss: 0.4223\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.4219 - val_accuracy: 0.8161 - val_loss: 0.4057\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8191 - loss: 0.3991 - val_accuracy: 0.8209 - val_loss: 0.3967\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.3909 - val_accuracy: 0.8226 - val_loss: 0.3969\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8348 - loss: 0.3746 - val_accuracy: 0.8251 - val_loss: 0.3919\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8358 - loss: 0.3737 - val_accuracy: 0.8211 - val_loss: 0.3947\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8378 - loss: 0.3651 - val_accuracy: 0.8253 - val_loss: 0.3894\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8393 - loss: 0.3639 - val_accuracy: 0.8258 - val_loss: 0.3892\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8449 - loss: 0.3523 - val_accuracy: 0.8233 - val_loss: 0.3924\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8488 - loss: 0.3489 - val_accuracy: 0.8237 - val_loss: 0.3872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2838eb7b070>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (80,000, 1)\n",
    "\n",
    "# Model architecture\n",
    "model6 = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "model6.add(Dense(64, input_dim=768, activation='gelu'))\n",
    "model6.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model6.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model6.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.575"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 2.6092 - val_accuracy: 0.7497 - val_loss: 0.6763\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6745 - loss: 0.6828 - val_accuracy: 0.7701 - val_loss: 0.6376\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.6690 - val_accuracy: 0.7713 - val_loss: 0.6238\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.6650 - val_accuracy: 0.7697 - val_loss: 0.6250\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.6613 - val_accuracy: 0.7731 - val_loss: 0.6204\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.6570 - val_accuracy: 0.7778 - val_loss: 0.6158\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.6567 - val_accuracy: 0.7791 - val_loss: 0.6110\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.6530 - val_accuracy: 0.7736 - val_loss: 0.6068\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.6518 - val_accuracy: 0.7720 - val_loss: 0.6073\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.6489 - val_accuracy: 0.7781 - val_loss: 0.6059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28390786b60>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "model7 = Sequential()\n",
    "model7.add(Dense(16, input_dim=768, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "model7.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model7.add(Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model7.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model7.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model7.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.335"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 2.9560 - val_accuracy: 0.7318 - val_loss: 0.7423\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.7259 - val_accuracy: 0.7374 - val_loss: 0.6974\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 0.7083 - val_accuracy: 0.7479 - val_loss: 0.6869\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.7084 - val_accuracy: 0.7512 - val_loss: 0.6788\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6154 - loss: 0.7066 - val_accuracy: 0.7529 - val_loss: 0.6805\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 0.7035 - val_accuracy: 0.7481 - val_loss: 0.6788\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6139 - loss: 0.7034 - val_accuracy: 0.7494 - val_loss: 0.6771\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 0.6995 - val_accuracy: 0.7584 - val_loss: 0.6755\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.7003 - val_accuracy: 0.7496 - val_loss: 0.6725\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6231 - loss: 0.6960 - val_accuracy: 0.7521 - val_loss: 0.6717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28391d38eb0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Dense(16, input_dim=768, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "\n",
    "model8.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model8.add(Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "\n",
    "model8.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model8.add(Dense(8, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model8.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model8.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model8.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.75"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6248 - loss: 2.6524 - val_accuracy: 0.7359 - val_loss: 0.6877\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.6898 - val_accuracy: 0.7562 - val_loss: 0.6440\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 0.6733 - val_accuracy: 0.7646 - val_loss: 0.6294\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6804 - loss: 0.6678 - val_accuracy: 0.7631 - val_loss: 0.6278\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6868 - loss: 0.6605 - val_accuracy: 0.7582 - val_loss: 0.6211\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6903 - loss: 0.6559 - val_accuracy: 0.7687 - val_loss: 0.6167\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6855 - loss: 0.6566 - val_accuracy: 0.7706 - val_loss: 0.6146\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6825 - loss: 0.6565 - val_accuracy: 0.7719 - val_loss: 0.6095\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.6497 - val_accuracy: 0.7707 - val_loss: 0.6069\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.6489 - val_accuracy: 0.7807 - val_loss: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28391f954b0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9 = Sequential()\n",
    "model9.add(Dense(16, input_dim=768, activation='gelu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "model9.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model9.add(Dense(16, activation='gelu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model9.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model9.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model9.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.845"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val(model9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.6022 - val_accuracy: 0.7928 - val_loss: 0.4498\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7899 - loss: 0.4561 - val_accuracy: 0.8082 - val_loss: 0.4187\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4224 - val_accuracy: 0.8192 - val_loss: 0.4075\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.4142 - val_accuracy: 0.8204 - val_loss: 0.3999\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4029 - val_accuracy: 0.8220 - val_loss: 0.3988\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4005 - val_accuracy: 0.8232 - val_loss: 0.3947\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.3960 - val_accuracy: 0.8235 - val_loss: 0.3927\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.3934 - val_accuracy: 0.8241 - val_loss: 0.3921\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.3898 - val_accuracy: 0.8246 - val_loss: 0.3908\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.3857 - val_accuracy: 0.8231 - val_loss: 0.3910\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.575"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10 = Sequential()\n",
    "model10.add(Dense(16, input_dim=768, activation='gelu'))\n",
    "model10.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model10.add(Dense(16, activation='gelu'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model10.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model10.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model10.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6211 - loss: 0.6545 - val_accuracy: 0.7650 - val_loss: 0.5019\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.5110 - val_accuracy: 0.7988 - val_loss: 0.4363\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4605 - val_accuracy: 0.8114 - val_loss: 0.4215\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8016 - loss: 0.4402 - val_accuracy: 0.8147 - val_loss: 0.4111\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.4319 - val_accuracy: 0.8181 - val_loss: 0.4073\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.4241 - val_accuracy: 0.8201 - val_loss: 0.4036\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4167 - val_accuracy: 0.8182 - val_loss: 0.4023\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8207 - loss: 0.4107 - val_accuracy: 0.8241 - val_loss: 0.4002\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.4040 - val_accuracy: 0.8259 - val_loss: 0.4023\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.4026 - val_accuracy: 0.8230 - val_loss: 0.3986\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.755"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model11 = Sequential()\n",
    "model11.add(Dense(16, input_dim=768, activation='gelu'))\n",
    "model11.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model11.add(Dense(8, activation='gelu'))\n",
    "model11.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model11.add(Dense(4, activation='gelu'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model11.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model11.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model11.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6788 - loss: 0.5993 - val_accuracy: 0.7909 - val_loss: 0.4512\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.4632 - val_accuracy: 0.8116 - val_loss: 0.4194\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.4361 - val_accuracy: 0.8154 - val_loss: 0.4110\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4252 - val_accuracy: 0.8212 - val_loss: 0.4018\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.4181 - val_accuracy: 0.8208 - val_loss: 0.4017\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4083 - val_accuracy: 0.8197 - val_loss: 0.3999\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4045 - val_accuracy: 0.8232 - val_loss: 0.3974\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.3983 - val_accuracy: 0.8237 - val_loss: 0.3981\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.3969 - val_accuracy: 0.8232 - val_loss: 0.3961\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.3983 - val_accuracy: 0.8224 - val_loss: 0.3948\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.815"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model12 = Sequential()\n",
    "model12.add(Dense(16, input_dim=768, activation='mish'))\n",
    "model12.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model12.add(Dense(8, activation='mish'))\n",
    "model12.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model12.add(Dense(4, activation='mish'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model12.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model12.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model12.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5693 - loss: 0.7054 - val_accuracy: 0.7112 - val_loss: 0.5728\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.5912 - val_accuracy: 0.7604 - val_loss: 0.5101\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5370 - val_accuracy: 0.7791 - val_loss: 0.4722\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7626 - loss: 0.4997 - val_accuracy: 0.7929 - val_loss: 0.4502\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4810 - val_accuracy: 0.8009 - val_loss: 0.4357\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 0.4670 - val_accuracy: 0.8050 - val_loss: 0.4255\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.4528 - val_accuracy: 0.8106 - val_loss: 0.4181\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.4402 - val_accuracy: 0.8129 - val_loss: 0.4130\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4324 - val_accuracy: 0.8158 - val_loss: 0.4092\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.4314 - val_accuracy: 0.8173 - val_loss: 0.4053\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.105"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13 = Sequential()\n",
    "model13.add(Dense(16, input_dim=768, activation='mish'))\n",
    "model13.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model13.add(Dense(8, activation='mish'))\n",
    "model13.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model13.add(Dense(4, activation='mish'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model13.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model13.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model13.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5463 - loss: 0.6925 - val_accuracy: 0.7502 - val_loss: 0.5517\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7009 - loss: 0.5723 - val_accuracy: 0.7997 - val_loss: 0.4495\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.5079 - val_accuracy: 0.8138 - val_loss: 0.4223\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.4759 - val_accuracy: 0.8154 - val_loss: 0.4152\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.4590 - val_accuracy: 0.8199 - val_loss: 0.4074\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8035 - loss: 0.4491 - val_accuracy: 0.8242 - val_loss: 0.4012\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4451 - val_accuracy: 0.8188 - val_loss: 0.4030\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4397 - val_accuracy: 0.8227 - val_loss: 0.3996\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.4351 - val_accuracy: 0.8244 - val_loss: 0.3968\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.4303 - val_accuracy: 0.8236 - val_loss: 0.3975\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.66"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model14 = Sequential()\n",
    "model14.add(Dense(8, input_dim=768, activation='mish'))\n",
    "model14.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "model14.add(Dense(4, activation='mish'))\n",
    "model14.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "model14.add(Dense(4, activation='mish'))\n",
    "model14.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "model14.add(Dense(2, activation='mish'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model14.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model14.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model14.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5464 - loss: 0.6857 - val_accuracy: 0.7541 - val_loss: 0.5741\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6859 - loss: 0.6004 - val_accuracy: 0.8034 - val_loss: 0.4495\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7618 - loss: 0.5234 - val_accuracy: 0.8096 - val_loss: 0.4306\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7856 - loss: 0.4889 - val_accuracy: 0.8155 - val_loss: 0.4183\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4797 - val_accuracy: 0.8184 - val_loss: 0.4137\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.4694 - val_accuracy: 0.8197 - val_loss: 0.4061\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4630 - val_accuracy: 0.8226 - val_loss: 0.4067\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8037 - loss: 0.4607 - val_accuracy: 0.8210 - val_loss: 0.4045\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4593 - val_accuracy: 0.8220 - val_loss: 0.4041\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.4534 - val_accuracy: 0.8230 - val_loss: 0.4011\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.33"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model15 = Sequential()\n",
    "model15.add(Dense(4, input_dim=768, activation='mish'))\n",
    "model15.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "model15.add(Dense(4, activation='mish'))\n",
    "model15.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "model15.add(Dense(4, activation='mish'))\n",
    "model15.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "model15.add(Dense(4, activation='mish'))\n",
    "model15.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "model15.add(Dense(2, activation='mish'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model15.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model15.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model15.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5513 - loss: 0.7802 - val_accuracy: 0.7120 - val_loss: 0.5744\n",
      "Epoch 2/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 0.6060 - val_accuracy: 0.7545 - val_loss: 0.5235\n",
      "Epoch 3/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 0.5563 - val_accuracy: 0.7764 - val_loss: 0.4898\n",
      "Epoch 4/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7460 - loss: 0.5280 - val_accuracy: 0.7864 - val_loss: 0.4688\n",
      "Epoch 5/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 0.5032 - val_accuracy: 0.7958 - val_loss: 0.4542\n",
      "Epoch 6/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7772 - loss: 0.4842 - val_accuracy: 0.8023 - val_loss: 0.4414\n",
      "Epoch 7/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.4708 - val_accuracy: 0.8071 - val_loss: 0.4327\n",
      "Epoch 8/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7934 - loss: 0.4635 - val_accuracy: 0.8087 - val_loss: 0.4255\n",
      "Epoch 9/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.4511 - val_accuracy: 0.8124 - val_loss: 0.4197\n",
      "Epoch 10/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4399 - val_accuracy: 0.8142 - val_loss: 0.4155\n",
      "Epoch 11/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.4387 - val_accuracy: 0.8173 - val_loss: 0.4108\n",
      "Epoch 12/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4330 - val_accuracy: 0.8202 - val_loss: 0.4073\n",
      "Epoch 13/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.4288 - val_accuracy: 0.8192 - val_loss: 0.4049\n",
      "Epoch 14/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4190 - val_accuracy: 0.8218 - val_loss: 0.4033\n",
      "Epoch 15/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.4242 - val_accuracy: 0.8236 - val_loss: 0.4010\n",
      "Epoch 16/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4173 - val_accuracy: 0.8239 - val_loss: 0.3989\n",
      "Epoch 17/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.4175 - val_accuracy: 0.8248 - val_loss: 0.3983\n",
      "Epoch 18/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4159 - val_accuracy: 0.8244 - val_loss: 0.3972\n",
      "Epoch 19/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.4150 - val_accuracy: 0.8247 - val_loss: 0.3948\n",
      "Epoch 20/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.4121 - val_accuracy: 0.8254 - val_loss: 0.3936\n",
      "Epoch 21/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4138 - val_accuracy: 0.8260 - val_loss: 0.3933\n",
      "Epoch 22/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.4055 - val_accuracy: 0.8263 - val_loss: 0.3924\n",
      "Epoch 23/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4081 - val_accuracy: 0.8239 - val_loss: 0.3920\n",
      "Epoch 24/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.4068 - val_accuracy: 0.8258 - val_loss: 0.3911\n",
      "Epoch 25/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4041 - val_accuracy: 0.8247 - val_loss: 0.3905\n",
      "Epoch 26/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.4033 - val_accuracy: 0.8269 - val_loss: 0.3902\n",
      "Epoch 27/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.4035 - val_accuracy: 0.8244 - val_loss: 0.3900\n",
      "Epoch 28/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8299 - loss: 0.3999 - val_accuracy: 0.8263 - val_loss: 0.3897\n",
      "Epoch 29/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8303 - loss: 0.3985 - val_accuracy: 0.8259 - val_loss: 0.3893\n",
      "Epoch 30/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.3970 - val_accuracy: 0.8256 - val_loss: 0.3891\n",
      "Epoch 31/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3953 - val_accuracy: 0.8281 - val_loss: 0.3884\n",
      "Epoch 32/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3937 - val_accuracy: 0.8256 - val_loss: 0.3874\n",
      "Epoch 33/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.3965 - val_accuracy: 0.8256 - val_loss: 0.3890\n",
      "Epoch 34/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.3925 - val_accuracy: 0.8251 - val_loss: 0.3891\n",
      "Epoch 35/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.3930 - val_accuracy: 0.8269 - val_loss: 0.3880\n",
      "Epoch 36/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.3905 - val_accuracy: 0.8271 - val_loss: 0.3873\n",
      "Epoch 37/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.3916 - val_accuracy: 0.8249 - val_loss: 0.3878\n",
      "Epoch 38/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.3913 - val_accuracy: 0.8253 - val_loss: 0.3870\n",
      "Epoch 39/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3873 - val_accuracy: 0.8264 - val_loss: 0.3869\n",
      "Epoch 40/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3849 - val_accuracy: 0.8282 - val_loss: 0.3866\n",
      "Epoch 41/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3918 - val_accuracy: 0.8266 - val_loss: 0.3870\n",
      "Epoch 42/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3876 - val_accuracy: 0.8288 - val_loss: 0.3862\n",
      "Epoch 43/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3841 - val_accuracy: 0.8276 - val_loss: 0.3860\n",
      "Epoch 44/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3882 - val_accuracy: 0.8267 - val_loss: 0.3864\n",
      "Epoch 45/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3825 - val_accuracy: 0.8264 - val_loss: 0.3859\n",
      "Epoch 46/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3836 - val_accuracy: 0.8269 - val_loss: 0.3855\n",
      "Epoch 47/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3843 - val_accuracy: 0.8268 - val_loss: 0.3861\n",
      "Epoch 48/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3833 - val_accuracy: 0.8265 - val_loss: 0.3868\n",
      "Epoch 49/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3789 - val_accuracy: 0.8268 - val_loss: 0.3855\n",
      "Epoch 50/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3770 - val_accuracy: 0.8251 - val_loss: 0.3851\n",
      "Epoch 51/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3815 - val_accuracy: 0.8249 - val_loss: 0.3866\n",
      "Epoch 52/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3826 - val_accuracy: 0.8278 - val_loss: 0.3849\n",
      "Epoch 53/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3781 - val_accuracy: 0.8275 - val_loss: 0.3853\n",
      "Epoch 54/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.3789 - val_accuracy: 0.8259 - val_loss: 0.3862\n",
      "Epoch 55/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3764 - val_accuracy: 0.8271 - val_loss: 0.3866\n",
      "Epoch 56/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.3783 - val_accuracy: 0.8274 - val_loss: 0.3871\n",
      "Epoch 57/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3738 - val_accuracy: 0.8264 - val_loss: 0.3853\n",
      "Epoch 58/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3782 - val_accuracy: 0.8269 - val_loss: 0.3853\n",
      "Epoch 59/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3736 - val_accuracy: 0.8287 - val_loss: 0.3850\n",
      "Epoch 60/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3717 - val_accuracy: 0.8290 - val_loss: 0.3852\n",
      "Epoch 61/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3740 - val_accuracy: 0.8266 - val_loss: 0.3865\n",
      "Epoch 62/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3753 - val_accuracy: 0.8263 - val_loss: 0.3861\n",
      "Epoch 63/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3792 - val_accuracy: 0.8292 - val_loss: 0.3857\n",
      "Epoch 64/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3756 - val_accuracy: 0.8291 - val_loss: 0.3864\n",
      "Epoch 65/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3746 - val_accuracy: 0.8278 - val_loss: 0.3854\n",
      "Epoch 66/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3723 - val_accuracy: 0.8263 - val_loss: 0.3856\n",
      "Epoch 67/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3740 - val_accuracy: 0.8275 - val_loss: 0.3863\n",
      "Epoch 68/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.3681 - val_accuracy: 0.8278 - val_loss: 0.3859\n",
      "Epoch 69/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8455 - loss: 0.3683 - val_accuracy: 0.8266 - val_loss: 0.3858\n",
      "Epoch 70/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3652 - val_accuracy: 0.8274 - val_loss: 0.3856\n",
      "Epoch 71/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3710 - val_accuracy: 0.8264 - val_loss: 0.3868\n",
      "Epoch 72/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3674 - val_accuracy: 0.8279 - val_loss: 0.3864\n",
      "Epoch 73/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3670 - val_accuracy: 0.8267 - val_loss: 0.3858\n",
      "Epoch 74/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3656 - val_accuracy: 0.8276 - val_loss: 0.3872\n",
      "Epoch 75/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3669 - val_accuracy: 0.8276 - val_loss: 0.3865\n",
      "Epoch 76/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.3695 - val_accuracy: 0.8285 - val_loss: 0.3876\n",
      "Epoch 77/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.3662 - val_accuracy: 0.8271 - val_loss: 0.3874\n",
      "Epoch 78/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.3655 - val_accuracy: 0.8250 - val_loss: 0.3872\n",
      "Epoch 79/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.3616 - val_accuracy: 0.8261 - val_loss: 0.3877\n",
      "Epoch 80/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3623 - val_accuracy: 0.8255 - val_loss: 0.3875\n",
      "Epoch 81/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.3617 - val_accuracy: 0.8263 - val_loss: 0.3878\n",
      "Epoch 82/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3610 - val_accuracy: 0.8279 - val_loss: 0.3865\n",
      "Epoch 83/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3619 - val_accuracy: 0.8269 - val_loss: 0.3865\n",
      "Epoch 84/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3649 - val_accuracy: 0.8279 - val_loss: 0.3867\n",
      "Epoch 85/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3583 - val_accuracy: 0.8266 - val_loss: 0.3873\n",
      "Epoch 86/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.3621 - val_accuracy: 0.8279 - val_loss: 0.3873\n",
      "Epoch 87/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.3626 - val_accuracy: 0.8256 - val_loss: 0.3880\n",
      "Epoch 88/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3558 - val_accuracy: 0.8276 - val_loss: 0.3884\n",
      "Epoch 89/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3586 - val_accuracy: 0.8273 - val_loss: 0.3881\n",
      "Epoch 90/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3578 - val_accuracy: 0.8264 - val_loss: 0.3885\n",
      "Epoch 91/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.3594 - val_accuracy: 0.8252 - val_loss: 0.3891\n",
      "Epoch 92/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3589 - val_accuracy: 0.8287 - val_loss: 0.3875\n",
      "Epoch 93/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.3587 - val_accuracy: 0.8259 - val_loss: 0.3881\n",
      "Epoch 94/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8496 - loss: 0.3572 - val_accuracy: 0.8262 - val_loss: 0.3884\n",
      "Epoch 95/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3603 - val_accuracy: 0.8245 - val_loss: 0.3892\n",
      "Epoch 96/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.3540 - val_accuracy: 0.8252 - val_loss: 0.3881\n",
      "Epoch 97/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3541 - val_accuracy: 0.8257 - val_loss: 0.3889\n",
      "Epoch 98/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.3543 - val_accuracy: 0.8242 - val_loss: 0.3891\n",
      "Epoch 99/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.3541 - val_accuracy: 0.8253 - val_loss: 0.3899\n",
      "Epoch 100/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.3538 - val_accuracy: 0.8241 - val_loss: 0.3904\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.38"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model16 = Sequential()\n",
    "model16.add(Dense(16, input_dim=768, activation='gelu'))\n",
    "model16.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model16.add(Dense(8, activation='gelu'))\n",
    "model16.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model16.add(Dense(4, activation='gelu'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model16.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model16.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model16.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5695 - loss: 0.6799 - val_accuracy: 0.7098 - val_loss: 0.5997\n",
      "Epoch 2/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.5948 - val_accuracy: 0.7498 - val_loss: 0.5334\n",
      "Epoch 3/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.5475 - val_accuracy: 0.7717 - val_loss: 0.4938\n",
      "Epoch 4/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.5130 - val_accuracy: 0.7858 - val_loss: 0.4686\n",
      "Epoch 5/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4921 - val_accuracy: 0.7954 - val_loss: 0.4510\n",
      "Epoch 6/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.4736 - val_accuracy: 0.8017 - val_loss: 0.4395\n",
      "Epoch 7/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: 0.4584 - val_accuracy: 0.8056 - val_loss: 0.4320\n",
      "Epoch 8/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.4470 - val_accuracy: 0.8101 - val_loss: 0.4244\n",
      "Epoch 9/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4413 - val_accuracy: 0.8129 - val_loss: 0.4203\n",
      "Epoch 10/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.4345 - val_accuracy: 0.8117 - val_loss: 0.4157\n",
      "Epoch 11/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4331 - val_accuracy: 0.8151 - val_loss: 0.4130\n",
      "Epoch 12/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4243 - val_accuracy: 0.8157 - val_loss: 0.4109\n",
      "Epoch 13/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4209 - val_accuracy: 0.8163 - val_loss: 0.4083\n",
      "Epoch 14/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4150 - val_accuracy: 0.8188 - val_loss: 0.4064\n",
      "Epoch 15/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.4142 - val_accuracy: 0.8194 - val_loss: 0.4043\n",
      "Epoch 16/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4123 - val_accuracy: 0.8206 - val_loss: 0.4039\n",
      "Epoch 17/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.4079 - val_accuracy: 0.8206 - val_loss: 0.4026\n",
      "Epoch 18/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4077 - val_accuracy: 0.8210 - val_loss: 0.4012\n",
      "Epoch 19/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.4040 - val_accuracy: 0.8211 - val_loss: 0.3998\n",
      "Epoch 20/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.4042 - val_accuracy: 0.8226 - val_loss: 0.3989\n",
      "Epoch 21/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.3986 - val_accuracy: 0.8241 - val_loss: 0.3991\n",
      "Epoch 22/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4008 - val_accuracy: 0.8236 - val_loss: 0.3974\n",
      "Epoch 23/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.4002 - val_accuracy: 0.8238 - val_loss: 0.3970\n",
      "Epoch 24/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.3982 - val_accuracy: 0.8249 - val_loss: 0.3962\n",
      "Epoch 25/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3979 - val_accuracy: 0.8237 - val_loss: 0.3959\n",
      "Epoch 26/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.3932 - val_accuracy: 0.8254 - val_loss: 0.3959\n",
      "Epoch 27/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.3958 - val_accuracy: 0.8248 - val_loss: 0.3959\n",
      "Epoch 28/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3888 - val_accuracy: 0.8261 - val_loss: 0.3948\n",
      "Epoch 29/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.3899 - val_accuracy: 0.8229 - val_loss: 0.3957\n",
      "Epoch 30/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.3940 - val_accuracy: 0.8244 - val_loss: 0.3940\n",
      "Epoch 31/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.3880 - val_accuracy: 0.8236 - val_loss: 0.3946\n",
      "Epoch 32/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3892 - val_accuracy: 0.8232 - val_loss: 0.3944\n",
      "Epoch 33/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.3864 - val_accuracy: 0.8253 - val_loss: 0.3948\n",
      "Epoch 34/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.3839 - val_accuracy: 0.8252 - val_loss: 0.3940\n",
      "Epoch 35/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.3829 - val_accuracy: 0.8251 - val_loss: 0.3938\n",
      "Epoch 36/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.3853 - val_accuracy: 0.8251 - val_loss: 0.3939\n",
      "Epoch 37/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 0.3842 - val_accuracy: 0.8253 - val_loss: 0.3931\n",
      "Epoch 38/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3806 - val_accuracy: 0.8254 - val_loss: 0.3928\n",
      "Epoch 39/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3840 - val_accuracy: 0.8246 - val_loss: 0.3929\n",
      "Epoch 40/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3788 - val_accuracy: 0.8239 - val_loss: 0.3932\n",
      "Epoch 41/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3822 - val_accuracy: 0.8272 - val_loss: 0.3925\n",
      "Epoch 42/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3763 - val_accuracy: 0.8258 - val_loss: 0.3922\n",
      "Epoch 43/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.3810 - val_accuracy: 0.8262 - val_loss: 0.3925\n",
      "Epoch 44/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.3802 - val_accuracy: 0.8277 - val_loss: 0.3917\n",
      "Epoch 45/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.3745 - val_accuracy: 0.8251 - val_loss: 0.3928\n",
      "Epoch 46/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3792 - val_accuracy: 0.8253 - val_loss: 0.3928\n",
      "Epoch 47/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3787 - val_accuracy: 0.8242 - val_loss: 0.3925\n",
      "Epoch 48/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.3721 - val_accuracy: 0.8257 - val_loss: 0.3928\n",
      "Epoch 49/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3742 - val_accuracy: 0.8256 - val_loss: 0.3933\n",
      "Epoch 50/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3709 - val_accuracy: 0.8264 - val_loss: 0.3935\n",
      "Epoch 51/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.3743 - val_accuracy: 0.8261 - val_loss: 0.3923\n",
      "Epoch 52/52\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.3736 - val_accuracy: 0.8248 - val_loss: 0.3925\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.145"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model17 = Sequential()\n",
    "model17.add(Dense(16, input_dim=768, activation='gelu'))\n",
    "model17.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model17.add(Dense(8, activation='gelu'))\n",
    "model17.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model17.add(Dense(4, activation='gelu'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model17.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model17.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model17.fit(X_train, y_train, epochs=52, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(model17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5622 - loss: 0.7011 - val_accuracy: 0.7149 - val_loss: 0.5987\n",
      "Epoch 2/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6928 - loss: 0.6027 - val_accuracy: 0.7546 - val_loss: 0.5282\n",
      "Epoch 3/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5477 - val_accuracy: 0.7745 - val_loss: 0.4835\n",
      "Epoch 4/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7580 - loss: 0.5116 - val_accuracy: 0.7879 - val_loss: 0.4599\n",
      "Epoch 5/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7703 - loss: 0.4942 - val_accuracy: 0.7955 - val_loss: 0.4446\n",
      "Epoch 6/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7825 - loss: 0.4787 - val_accuracy: 0.8016 - val_loss: 0.4346\n",
      "Epoch 7/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.4636 - val_accuracy: 0.8040 - val_loss: 0.4270\n",
      "Epoch 8/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.4545 - val_accuracy: 0.8092 - val_loss: 0.4198\n",
      "Epoch 9/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.4489 - val_accuracy: 0.8127 - val_loss: 0.4158\n",
      "Epoch 10/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4393 - val_accuracy: 0.8139 - val_loss: 0.4112\n",
      "Epoch 11/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.4366 - val_accuracy: 0.8149 - val_loss: 0.4085\n",
      "Epoch 12/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4317 - val_accuracy: 0.8178 - val_loss: 0.4059\n",
      "Epoch 13/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4301 - val_accuracy: 0.8183 - val_loss: 0.4034\n",
      "Epoch 14/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.4207 - val_accuracy: 0.8188 - val_loss: 0.4023\n",
      "Epoch 15/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.4203 - val_accuracy: 0.8194 - val_loss: 0.4013\n",
      "Epoch 16/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4153 - val_accuracy: 0.8198 - val_loss: 0.3983\n",
      "Epoch 17/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4170 - val_accuracy: 0.8196 - val_loss: 0.3977\n",
      "Epoch 18/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8207 - loss: 0.4144 - val_accuracy: 0.8224 - val_loss: 0.3961\n",
      "Epoch 19/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.4058 - val_accuracy: 0.8235 - val_loss: 0.3953\n",
      "Epoch 20/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4079 - val_accuracy: 0.8246 - val_loss: 0.3946\n",
      "Epoch 21/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.4052 - val_accuracy: 0.8231 - val_loss: 0.3947\n",
      "Epoch 22/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.4047 - val_accuracy: 0.8241 - val_loss: 0.3940\n",
      "Epoch 23/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.4033 - val_accuracy: 0.8236 - val_loss: 0.3937\n",
      "Epoch 24/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.3926 - val_accuracy: 0.8254 - val_loss: 0.3928\n",
      "Epoch 25/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3961 - val_accuracy: 0.8248 - val_loss: 0.3922\n",
      "Epoch 26/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.3950 - val_accuracy: 0.8267 - val_loss: 0.3917\n",
      "Epoch 27/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.3928 - val_accuracy: 0.8264 - val_loss: 0.3914\n",
      "Epoch 28/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.3926 - val_accuracy: 0.8268 - val_loss: 0.3913\n",
      "Epoch 29/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.3944 - val_accuracy: 0.8258 - val_loss: 0.3918\n",
      "Epoch 30/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.3911 - val_accuracy: 0.8254 - val_loss: 0.3913\n",
      "Epoch 31/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.3974 - val_accuracy: 0.8267 - val_loss: 0.3902\n",
      "Epoch 32/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3909 - val_accuracy: 0.8282 - val_loss: 0.3903\n",
      "Epoch 33/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.3892 - val_accuracy: 0.8260 - val_loss: 0.3909\n",
      "Epoch 34/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3883 - val_accuracy: 0.8255 - val_loss: 0.3903\n",
      "Epoch 35/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.3851 - val_accuracy: 0.8271 - val_loss: 0.3897\n",
      "Epoch 36/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.3836 - val_accuracy: 0.8279 - val_loss: 0.3901\n",
      "Epoch 37/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.3870 - val_accuracy: 0.8289 - val_loss: 0.3895\n",
      "Epoch 38/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.3862 - val_accuracy: 0.8278 - val_loss: 0.3893\n",
      "Epoch 39/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3798 - val_accuracy: 0.8291 - val_loss: 0.3892\n",
      "Epoch 40/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.3813 - val_accuracy: 0.8262 - val_loss: 0.3904\n",
      "Epoch 41/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3801 - val_accuracy: 0.8277 - val_loss: 0.3900\n",
      "Epoch 42/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3781 - val_accuracy: 0.8285 - val_loss: 0.3889\n",
      "Epoch 43/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.3860 - val_accuracy: 0.8276 - val_loss: 0.3889\n",
      "Epoch 44/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3842 - val_accuracy: 0.8281 - val_loss: 0.3886\n",
      "Epoch 45/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.3774 - val_accuracy: 0.8281 - val_loss: 0.3885\n",
      "Epoch 46/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3770 - val_accuracy: 0.8270 - val_loss: 0.3893\n",
      "Epoch 47/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3785 - val_accuracy: 0.8293 - val_loss: 0.3884\n",
      "Epoch 48/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.3713 - val_accuracy: 0.8276 - val_loss: 0.3893\n",
      "Epoch 49/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.3778 - val_accuracy: 0.8279 - val_loss: 0.3886\n",
      "Epoch 50/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3777 - val_accuracy: 0.8282 - val_loss: 0.3887\n",
      "Epoch 51/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3756 - val_accuracy: 0.8273 - val_loss: 0.3887\n",
      "Epoch 52/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.3750 - val_accuracy: 0.8275 - val_loss: 0.3882\n",
      "Epoch 53/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3764 - val_accuracy: 0.8267 - val_loss: 0.3889\n",
      "Epoch 54/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.3734 - val_accuracy: 0.8278 - val_loss: 0.3897\n",
      "Epoch 55/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3733 - val_accuracy: 0.8283 - val_loss: 0.3894\n",
      "Epoch 56/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.3741 - val_accuracy: 0.8278 - val_loss: 0.3899\n",
      "Epoch 57/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3692 - val_accuracy: 0.8283 - val_loss: 0.3890\n",
      "Epoch 58/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3711 - val_accuracy: 0.8279 - val_loss: 0.3892\n",
      "Epoch 59/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3734 - val_accuracy: 0.8275 - val_loss: 0.3894\n",
      "Epoch 60/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3715 - val_accuracy: 0.8273 - val_loss: 0.3906\n",
      "Epoch 61/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3696 - val_accuracy: 0.8252 - val_loss: 0.3904\n",
      "Epoch 62/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.3671 - val_accuracy: 0.8282 - val_loss: 0.3892\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.875"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model18 = Sequential()\n",
    "model18.add(Dense(16, input_dim=768, activation='gelu'))\n",
    "model18.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model18.add(Dense(8, activation='gelu'))\n",
    "model18.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "model18.add(Dense(4, activation='gelu'))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "model18.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model18.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model18.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "accuracy_val(model18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model, model0, model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12, model13, model14, model15, model16, model17, model18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step\n"
     ]
    }
   ],
   "source": [
    "model_results = []\n",
    "\n",
    "for Model in models:\n",
    "    model_results.append((Model.count_params(), accuracy_val(Model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = [], []\n",
    "\n",
    "for Model in model_results:\n",
    "    x.append(Model[0])\n",
    "    y.append(Model[1])\n",
    "\n",
    "plt.scatter(x, y, label = 'performance', color=\"blue\")\n",
    "\n",
    "plt.title(\"Model size vs performance\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = [], []\n",
    "\n",
    "for Model in model_results:\n",
    "    if (Model[0] < 100000):\n",
    "        x.append(Model[0])\n",
    "        y.append(Model[1])\n",
    "\n",
    "plt.scatter(x, y, label = 'performance', color=\"blue\")\n",
    "\n",
    "plt.title(\"Model size vs performance\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(919553, 78.83),\n",
       " (558081, 81.43),\n",
       " (558081, 81.105),\n",
       " (558081, 84.48),\n",
       " (886529, 49.004999999999995),\n",
       " (394241, 49.39),\n",
       " (49281, 81.78999999999999),\n",
       " (49281, 81.575),\n",
       " (12593, 76.335),\n",
       " (12721, 73.75),\n",
       " (12593, 76.845),\n",
       " (12593, 81.575),\n",
       " (12481, 81.755),\n",
       " (12481, 81.815),\n",
       " (12481, 81.105),\n",
       " (6221, 81.66),\n",
       " (3149, 81.33),\n",
       " (12481, 81.38),\n",
       " (12481, 82.145),\n",
       " (12481, 81.875)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_family = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6333 - loss: 0.6372 - val_accuracy: 0.7819 - val_loss: 0.4630\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7774 - loss: 0.4748 - val_accuracy: 0.8067 - val_loss: 0.4240\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8012 - loss: 0.4364 - val_accuracy: 0.8129 - val_loss: 0.4076\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8157 - loss: 0.4066 - val_accuracy: 0.8198 - val_loss: 0.3980\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8259 - loss: 0.3893 - val_accuracy: 0.8221 - val_loss: 0.3926\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8350 - loss: 0.3739 - val_accuracy: 0.8214 - val_loss: 0.3909\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8378 - loss: 0.3648 - val_accuracy: 0.8224 - val_loss: 0.3872\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8462 - loss: 0.3535 - val_accuracy: 0.8234 - val_loss: 0.3875\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8481 - loss: 0.3457 - val_accuracy: 0.8251 - val_loss: 0.3868\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8536 - loss: 0.3389 - val_accuracy: 0.8226 - val_loss: 0.3881\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.815"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "modeli = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "modeli.add(Dense(512, input_dim=768, activation='relu'))\n",
    "modeli.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "modeli.add(Dense(256, activation='gelu'))\n",
    "modeli.add(Dropout(0.3))\n",
    "modeli.add(Dense(128, activation='gelu'))\n",
    "modeli.add(Dropout(0.3))\n",
    "modeli.add(Dense(64, activation='gelu'))\n",
    "modeli.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "modeli.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "modeli.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "modeli.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(modeli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_family.append(modeli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6135 - loss: 0.6586 - val_accuracy: 0.7717 - val_loss: 0.4798\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.7620 - loss: 0.4962 - val_accuracy: 0.7987 - val_loss: 0.4368\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7925 - loss: 0.4501 - val_accuracy: 0.8103 - val_loss: 0.4185\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8077 - loss: 0.4243 - val_accuracy: 0.8184 - val_loss: 0.4058\n",
      "Epoch 5/10\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8178 - loss: 0.4079"
     ]
    }
   ],
   "source": [
    "# X_train is my 80,000 x 768 BERT vectors\n",
    "# y_train is my binary labels (0 or 1) with shape (100000, 1)\n",
    "\n",
    "# Model architecture\n",
    "modeli = Sequential()\n",
    "\n",
    "# Input layer: (768,) is the shape of each BERT vector\n",
    "modeli.add(Dense(256, input_dim=768, activation='relu'))\n",
    "modeli.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "modeli.add(Dense(256, activation='gelu'))\n",
    "modeli.add(Dropout(0.3))\n",
    "modeli.add(Dense(128, activation='gelu'))\n",
    "modeli.add(Dropout(0.3))\n",
    "modeli.add(Dense(64, activation='gelu'))\n",
    "modeli.add(Dropout(0.3))\n",
    "\n",
    "# Output layer: single neuron with sigmoid activation for binary classification\n",
    "modeli.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "modeli.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "modeli.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "accuracy_val(modeli)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
