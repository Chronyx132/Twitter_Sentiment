{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT1244 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as re\n",
    "import heapq as heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import random as random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 10\n",
      "Test accuracy: 0.7615\n",
      "\n",
      "RESULTS:\n",
      "Accuracy:  0.7615\n",
      "Precision: 0.7681\n",
      "Recall:    0.7492\n",
      "F1-Score:  0.7585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load and clean data\n",
    "cleanedtweets = pd.read_csv(\"../Data/Raw/CleanedTweets.csv\")\n",
    "cleanedtweets[\"processed_text\"] = cleanedtweets[\"processed_text\"].fillna(\"\")\n",
    "\n",
    "X = cleanedtweets['processed_text']\n",
    "y = cleanedtweets['sentiment']\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid\n",
    "params = {\n",
    "    'mnb__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "# Grid search with 5-fold CV\n",
    "grid_search = GridSearchCV(nb, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best result\n",
    "print(\"Best alpha:\", grid_search.best_params_['mnb__alpha'])\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "\n",
    "results = {}\n",
    "results['acc'] = accuracy_score(y_test, y_pred)\n",
    "results['prec'] = precision_score(y_test, y_pred)\n",
    "results['rec'] = recall_score(y_test, y_pred)\n",
    "results['f1'] =f1_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRESULTS:\")\n",
    "print(f\"Accuracy:  {results['acc']:.4f}\")\n",
    "print(f\"Precision: {results['prec']:.4f}\")\n",
    "print(f\"Recall:    {results['rec']:.4f}\")\n",
    "print(f\"F1-Score:  {results['f1']:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
